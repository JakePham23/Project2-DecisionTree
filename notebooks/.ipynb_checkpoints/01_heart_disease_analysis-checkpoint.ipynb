{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aa3b877",
   "metadata": {},
   "source": [
    "# Phân tích bộ dữ liệu `Heart Disease`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a6a9b2",
   "metadata": {},
   "source": [
    "## 1. Preparing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab1af0ff",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Áp dụng One-Hot Encoding...\n",
      "Số lượng features sau One-Hot Encoding: 30\n",
      "\n",
      "Xử lý các giá trị bị thiếu...\n",
      "\n",
      "Chia dữ liệu thành tập train và test...\n",
      "Đang tạo biểu đồ gốc...\n",
      "Biểu đồ đã được lưu tại: ../outputs/heart_disease/charts/class_original.png\n",
      "Đang tạo các biểu đồ phân phối lớp...\n",
      "Biểu đồ đã được lưu tại: ../outputs/heart_disease/charts/class_distribution_60_40.png\n",
      "Biểu đồ đã được lưu tại: ../outputs/heart_disease/charts/class_distribution_40_60.png\n",
      "Biểu đồ đã được lưu tại: ../outputs/heart_disease/charts/class_distribution_80_20.png\n",
      "Biểu đồ đã được lưu tại: ../outputs/heart_disease/charts/class_distribution_90_10.png\n",
      "Hoàn tất xử lý dữ liệu!\n"
     ]
    }
   ],
   "source": [
    "# %pip install numpy matplotlib seaborn graphviz\n",
    "\n",
    "# --- Thư viện cơ bản ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import graphviz\n",
    "import os\n",
    "\n",
    "# --- Thư viện cho Machine Learning ---\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# --- Định nghĩa các đường dẫn ---\n",
    "# Đi từ `notebooks` ra ngoài một cấp để thấy các thư mục khác\n",
    "DATA_PATH = '../data/heart_disease.csv'\n",
    "OUTPUT_DIR = '../outputs/heart_disease/'\n",
    "# Tạo thư mục output nếu nó chưa tồn tại\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# (Tùy chọn) Thêm thư mục src vào path để import các hàm từ utils.py\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from src.utils import plot_label_distribution, plot_label_original, build_decision_tree, evaluating_decision_tree_class # Ví dụ nếu bạn có hàm riêng\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# --- Tải và khám phá dữ liệu ---\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Chuyển cột 'num' thành nhãn nhị phân (0: không bệnh, 1: có bệnh)\n",
    "df['num'] = (df['num'] > 0).astype(int)\n",
    "\n",
    "# 1. Tách features và labels\n",
    "features = df.drop('num', axis=1)\n",
    "labels = df['num']\n",
    "\n",
    "# 2. Áp dụng One-Hot Encoding\n",
    "print(\"Áp dụng One-Hot Encoding...\")\n",
    "features_encoded = pd.get_dummies(features)\n",
    "print(f\"Số lượng features sau One-Hot Encoding: {features_encoded.shape[1]}\")\n",
    "\n",
    "# 3. Xử lý giá trị thiếu (NaN)\n",
    "print(\"\\nXử lý các giá trị bị thiếu...\")\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "# Dùng features_final để lưu lại kết quả cuối cùng\n",
    "features_final = pd.DataFrame(imputer.fit_transform(features_encoded), columns=features_encoded.columns)\n",
    "\n",
    "# 4. Chia dữ liệu train/test (SỬ DỤNG features_final)\n",
    "print(\"\\nChia dữ liệu thành tập train và test...\")\n",
    "\n",
    "# Phân chia train và test theo tỷ lệ\n",
    "feature_train_60, feature_test_40, label_train_60, label_test_40 = train_test_split(\n",
    "        features_final, labels, test_size=0.4, shuffle=True, stratify=labels, random_state=42)\n",
    "\n",
    "feature_train_40, feature_test_60, label_train_40, label_test_60 = train_test_split(\n",
    "        features_final, labels, test_size=0.6, shuffle=True, stratify=labels, random_state=42)\n",
    "\n",
    "feature_train_80, feature_test_20, label_train_80, label_test_20 = train_test_split(\n",
    "        features_final, labels, test_size=0.2, shuffle=True, stratify=labels, random_state=42)\n",
    "\n",
    "feature_train_90, feature_test_10, label_train_90, label_test_10 = train_test_split(\n",
    "        features_final, labels, test_size=0.1, shuffle=True, stratify=labels, random_state=42)\n",
    "\n",
    "#Tạo biểu đồ ban đầu\n",
    "print(\"Đang tạo biểu đồ gốc...\")\n",
    "plot_label_original(labels, OUTPUT_DIR)\n",
    "\n",
    "print(\"Đang tạo các biểu đồ phân phối lớp...\")\n",
    "# Tạo các biểu đồ được phân chia\n",
    "plot_label_distribution(label_train_60, label_test_40, 60, 40, OUTPUT_DIR)\n",
    "plot_label_distribution(label_train_40, label_test_60, 40, 60, OUTPUT_DIR)\n",
    "plot_label_distribution(label_train_80, label_test_20, 80, 20, OUTPUT_DIR)\n",
    "plot_label_distribution(label_train_90, label_test_10, 90, 10, OUTPUT_DIR)\n",
    "\n",
    "print(\"Hoàn tất xử lý dữ liệu!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959635b9",
   "metadata": {},
   "source": [
    "## 2. Building the decision tree classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2c41d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang tạo confusion matrix 60/40...\n",
      "Đã tạo decision tree tại ../outputs/heart_disease/trees/decision_tree_60_40\n",
      "Đang tạo confusion matrix 40/60...\n",
      "Đã tạo decision tree tại ../outputs/heart_disease/trees/decision_tree_40_60\n",
      "Đang tạo confusion matrix 80/20...\n",
      "Đã tạo decision tree tại ../outputs/heart_disease/trees/decision_tree_80_20\n",
      "Đang tạo confusion matrix 90/10...\n",
      "Đã tạo decision tree tại ../outputs/heart_disease/trees/decision_tree_90_10\n"
     ]
    }
   ],
   "source": [
    "print(\"Đang tạo confusion matrix 60/40...\")\n",
    "clf_60_40 = build_decision_tree(features_final, feature_train_60, label_train_60, 60, 40, OUTPUT_DIR)\n",
    "\n",
    "print(\"Đang tạo confusion matrix 40/60...\")\n",
    "clf_40_60 = build_decision_tree(features_final, feature_train_40, label_train_40, 40, 60, OUTPUT_DIR)\n",
    "\n",
    "print(\"Đang tạo confusion matrix 80/20...\")\n",
    "clf_80_20 = build_decision_tree(features_final, feature_train_80, label_train_80, 80, 20, OUTPUT_DIR)\n",
    "\n",
    "print(\"Đang tạo confusion matrix 90/10...\")\n",
    "clf_90_10 = build_decision_tree(features_final, feature_train_90, label_train_90, 90, 10, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb481cac",
   "metadata": {},
   "source": [
    "## 3. Evaluating the decision tree classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f7151a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang tạo Classification Report và Confusion Matrix cho test 60\n",
      "Classification Report (40/60) đã được lưu tại: ../outputs/heart_disease/reports//classification_report_40_60.txt\n",
      "Confusion Matrix (Depth=12, 40/60 Split) đã được lưu tại: ../outputs/heart_disease/matrices/confusion_matrix_40_60.png\n",
      "Đang tạo Classification Report và Confusion Matrix cho test 40\n",
      "Classification Report (60/40) đã được lưu tại: ../outputs/heart_disease/reports//classification_report_60_40.txt\n",
      "Confusion Matrix (Depth=17, 60/40 Split) đã được lưu tại: ../outputs/heart_disease/matrices/confusion_matrix_60_40.png\n",
      "Đang tạo Classification Report và Confusion Matrix cho test 20\n",
      "Classification Report (80/20) đã được lưu tại: ../outputs/heart_disease/reports//classification_report_80_20.txt\n",
      "Confusion Matrix (Depth=16, 80/20 Split) đã được lưu tại: ../outputs/heart_disease/matrices/confusion_matrix_80_20.png\n",
      "Đang tạo Classification Report và Confusion Matrix cho test 10\n",
      "Classification Report (90/10) đã được lưu tại: ../outputs/heart_disease/reports//classification_report_90_10.txt\n",
      "Confusion Matrix (Depth=13, 90/10 Split) đã được lưu tại: ../outputs/heart_disease/matrices/confusion_matrix_90_10.png\n"
     ]
    }
   ],
   "source": [
    "print(\"Đang tạo Classification Report và Confusion Matrix cho test 60\")\n",
    "evaluating_decision_tree_class(clf_40_60, feature_test_60, label_test_60, 40, 60, OUTPUT_DIR)\n",
    "\n",
    "print(\"Đang tạo Classification Report và Confusion Matrix cho test 40\")\n",
    "evaluating_decision_tree_class(clf_60_40, feature_test_40, label_test_40, 60, 40, OUTPUT_DIR)\n",
    "\n",
    "print(\"Đang tạo Classification Report và Confusion Matrix cho test 20\")\n",
    "evaluating_decision_tree_class(clf_80_20, feature_test_20, label_test_20, 80, 20, OUTPUT_DIR)\n",
    "\n",
    "print(\"Đang tạo Classification Report và Confusion Matrix cho test 10\")\n",
    "evaluating_decision_tree_class(clf_90_10, feature_test_10, label_test_10, 90, 10, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bcb395",
   "metadata": {},
   "source": [
    "## 4. The depth and accuracy of a decision tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c19385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Độ sâu\n",
    "depths = [None, 2, 3, 4, 5, 6, 7]\n",
    "accuracies = []\n",
    "\n",
    "output_dir = '../outputs/heart_disease/acc/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "results = []\n",
    "\n",
    "for depth in depths:\n",
    "    str_depth = f\" với độ sâu là {depth} \" if depth is not None else \"\"\n",
    "    print(f\"Đang tạo cây quyết định{str_depth}...\")\n",
    "    clf = DecisionTreeClassifier(criterion='entropy', max_depth=depth, random_state=42)\n",
    "    clf.fit(feature_train_80, label_train_80)\n",
    "    y_pred = clf.predict(feature_test_20)\n",
    "    acc = accuracy_score(label_test_20, y_pred)\n",
    "    accuracies.append(acc)\n",
    "\n",
    "    results.append({\n",
    "        \"max_depth\": str(depth),\n",
    "        \"Accuracy\": acc\n",
    "    })\n",
    "    \n",
    "    # Vẽ và lưu cây\n",
    "    dot_data = export_graphviz(clf, out_file=None, feature_names=features_final.columns, class_names=[\"0\", \"1\"],\n",
    "                               filled=True, rounded=True, special_characters=True)\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    filename = f\"{output_dir}tree_depth_{depth if depth else 'None'}\"\n",
    "    graph.render(filename=filename, format=\"pdf\", cleanup=True)\n",
    "    print(f\"Cây đã được lưu tại {filename}\")\n",
    "\n",
    "print(\"Đang tạo bảng accuracy_score...\")\n",
    "\n",
    "# Chuyển sang dict với key là max_depth, value là accuracy\n",
    "accuracy_dict = {entry[\"max_depth\"]: entry[\"Accuracy\"] for entry in results}\n",
    "\n",
    "# Tạo DataFrame dạng 1 dòng, với index là Accuracy\n",
    "results_df = pd.DataFrame([accuracy_dict], index=[\"Accuracy\"])\n",
    "results_df.columns.name = \"max_depth\"  # Gán tên cột\n",
    "\n",
    "# Lưu vào CSV\n",
    "results_df.to_csv(f\"{output_dir}accuracy_score.csv\", index=True, index_label=\"max_depth\")\n",
    "print(f\"Đã tạo bảng accuracy_score tại {output_dir}accuracy_score.csv\")\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot([str(d) for d in depths], accuracies, marker='o')\n",
    "plt.title(\"Chart\")\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid(True)\n",
    "plt.savefig(f\"{output_dir}accuracy_vs_depth.png\")\n",
    "plt.close()\n",
    "print(f\"Đã tạo biểu đồ accuracy_score tại {output_dir}accuracy_vs_depth.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
