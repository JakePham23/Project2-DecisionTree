{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aa3b877",
   "metadata": {},
   "source": [
    "# Phân tích bộ dữ liệu `Heart Disease`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a6a9b2",
   "metadata": {},
   "source": [
    "## 1. Preparing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab1af0ff",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Áp dụng One-Hot Encoding...\n",
      "Số lượng features sau One-Hot Encoding: 30\n",
      "\n",
      "Xử lý các giá trị bị thiếu...\n",
      "\n",
      "Thông tin dữ liệu sau khi xử lý hoàn tất:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 920 entries, 0 to 919\n",
      "Data columns (total 30 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   id                        920 non-null    float64\n",
      " 1   age                       920 non-null    float64\n",
      " 2   trestbps                  920 non-null    float64\n",
      " 3   chol                      920 non-null    float64\n",
      " 4   thalch                    920 non-null    float64\n",
      " 5   oldpeak                   920 non-null    float64\n",
      " 6   ca                        920 non-null    float64\n",
      " 7   sex_Female                920 non-null    float64\n",
      " 8   sex_Male                  920 non-null    float64\n",
      " 9   dataset_Cleveland         920 non-null    float64\n",
      " 10  dataset_Hungary           920 non-null    float64\n",
      " 11  dataset_Switzerland       920 non-null    float64\n",
      " 12  dataset_VA Long Beach     920 non-null    float64\n",
      " 13  cp_asymptomatic           920 non-null    float64\n",
      " 14  cp_atypical angina        920 non-null    float64\n",
      " 15  cp_non-anginal            920 non-null    float64\n",
      " 16  cp_typical angina         920 non-null    float64\n",
      " 17  fbs_False                 920 non-null    float64\n",
      " 18  fbs_True                  920 non-null    float64\n",
      " 19  restecg_lv hypertrophy    920 non-null    float64\n",
      " 20  restecg_normal            920 non-null    float64\n",
      " 21  restecg_st-t abnormality  920 non-null    float64\n",
      " 22  exang_False               920 non-null    float64\n",
      " 23  exang_True                920 non-null    float64\n",
      " 24  slope_downsloping         920 non-null    float64\n",
      " 25  slope_flat                920 non-null    float64\n",
      " 26  slope_upsloping           920 non-null    float64\n",
      " 27  thal_fixed defect         920 non-null    float64\n",
      " 28  thal_normal               920 non-null    float64\n",
      " 29  thal_reversable defect    920 non-null    float64\n",
      "dtypes: float64(30)\n",
      "memory usage: 215.8 KB\n",
      "\n",
      "Chia dữ liệu thành tập train và test...\n",
      "Hoàn tất xử lý dữ liệu!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %pip install numpy matplotlib seaborn graphviz\n",
    "\n",
    "# --- Thư viện cơ bản ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import graphviz\n",
    "import os\n",
    "\n",
    "# --- Thư viện cho Machine Learning ---\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# --- Định nghĩa các đường dẫn ---\n",
    "# Đi từ `notebooks` ra ngoài một cấp để thấy các thư mục khác\n",
    "DATA_PATH = '../data/heart_disease.csv'\n",
    "OUTPUT_IMAGE_DIR = '../outputs/images/heart_disease/'\n",
    "# Tạo thư mục output nếu nó chưa tồn tại\n",
    "os.makedirs(OUTPUT_IMAGE_DIR, exist_ok=True)\n",
    "\n",
    "# (Tùy chọn) Thêm thư mục src vào path để import các hàm từ utils.py\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "# from src.utils import your_custom_function # Ví dụ nếu bạn có hàm riêng\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# --- Tải và khám phá dữ liệu ---\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Chuyển cột 'num' thành nhãn nhị phân (0: không bệnh, 1: có bệnh)\n",
    "df['num'] = (df['num'] > 0).astype(int)\n",
    "\n",
    "# 1. Tách features và labels\n",
    "features = df.drop('num', axis=1)\n",
    "labels = df['num']\n",
    "\n",
    "# 2. Áp dụng One-Hot Encoding\n",
    "print(\"Áp dụng One-Hot Encoding...\")\n",
    "features_encoded = pd.get_dummies(features)\n",
    "print(f\"Số lượng features sau One-Hot Encoding: {features_encoded.shape[1]}\")\n",
    "\n",
    "\n",
    "\n",
    "# 3. Xử lý giá trị thiếu (NaN)\n",
    "print(\"\\nXử lý các giá trị bị thiếu...\")\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "# Dùng features_final để lưu lại kết quả cuối cùng\n",
    "features_final = pd.DataFrame(imputer.fit_transform(features_encoded), columns=features_encoded.columns)\n",
    "\n",
    "\n",
    "# Kiểm tra lại lần cuối để chắc chắn không còn giá trị thiếu\n",
    "print(\"\\nThông tin dữ liệu sau khi xử lý hoàn tất:\")\n",
    "features_final.info()\n",
    "\n",
    "\n",
    "# 4. Chia dữ liệu train/test (SỬ DỤNG features_final)\n",
    "print(\"\\nChia dữ liệu thành tập train và test...\")\n",
    "feature_train, feature_test, label_train, label_test = train_test_split(\n",
    "    features_final, labels, test_size=0.2, shuffle=True, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Hoàn tất xử lý dữ liệu!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959635b9",
   "metadata": {},
   "source": [
    "## 2. Building the decision tree classifiers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb481cac",
   "metadata": {},
   "source": [
    "## 3. Evaluating the decision tree classifiers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bcb395",
   "metadata": {},
   "source": [
    "## 4. The depth and accuracy of a decision tree\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
